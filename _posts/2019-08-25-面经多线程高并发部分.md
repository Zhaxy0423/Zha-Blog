---
layout:     post
title:      JAVA后台开发面经整理——多线程高并发部分
subtitle:   秋招待上岸
date:       2019-08-22
author:     Zhaxy
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - JAVA
    - 秋招
    - 多线程
    - 面经
---

## java内存模型、线程池类型及原理、多线程使用共享资源怎么解决、锁的实现机制、死锁及必要条件、synchorized锁实例锁的是什么，锁static锁的是什么？
### 问题一：多线程基础问题
#### 1.1 线程与进程的区别
    (1)进程是程序的一次执行过程，是系统运行程序分配资源的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。在Java中，当我们启动main函数时其实就是启动了一个JVM的进程。
    (2)线程是调度系统资源的基本单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈。
    【区别】
    线程是进程划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。

#### 1.2 守护线程和本地线程区别
    java中的线程分为两种：守护线程（Daemon）和用户线程（User）。任何线程都可以设置为守护线程和用户线程，通过方法Thread.setDaemon(bool on)；true则把该线程设置为守护线程，反之则为用户线程。Thread.setDaemon()必须在Thread.start()之前调用，否则运行时会抛出异常。
    【区别----JVM何时离开】
    Daemon是为其他线程提供服务，如果全部的User Thread已经撤离，Daemon没有可服务的线程，JVM撤离。也可以理解为守护线程是JVM自动创建的线程（但不一定），用户线程是程序创建的线程；比如JVM的垃圾回收线程是一个守护线程，当所有线程已经撤离，不再产生垃圾，守护线程自然就没事可干了，当垃圾回收线程是Java虚拟机上仅剩的线程时，Java虚拟机会自动离开。

#### 1.3 线程的生命周期和状态
    (1)线程创建之后它将处于NEW(新建)状态，调用start()方法后开始运行，线程这时候处于 READY(可运行状态)。可运行状态的线程获得了CPU时间片(timeslice)后就处于RUNNING(运行状态)。
    (2)当线程执行wait()方法之后，线程进入WAITING(等待)状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而TIME_WAITING(超时等待)状态相当于在等待状态的基础上增加了超时限制，比如通过sleep(long millis)方法或 wait(long millis)方法可以将Java线程置于TIMED WAITING状态。当超时时间到达后Java线程将会返回到RUNNABLE状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到BLOCKED(阻塞)状态。线程在执行Runnable的run()方法之后将会进入到TERMINATED(终止)状态。

#### 1.4 sleep()方法和wait()方法区别和共同点
    (1)两者最主要的区别在于：sleep方法没有释放锁，而wait方法释放了锁 。
    (2)两者都可以暂停线程的执行。
    (3)Wait通常被用于线程间交互/通信，sleep通常被用于暂停执行。
    (4)wait()方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的notify()或者notifyAll()方法。sleep()方法执行完成后，线程会自动苏醒。或者可以使用wait(long timeout)超时后线程会自动苏醒。

#### 1.5 为什么我们调用start()方法时会执行run()方法，而不能直接调用run()方法？
    (1)new一个Thread，线程进入了新建状态；调用start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。start()会执行线程的相应准备工作，然后自动执行run()方法的内容，这是真正的多线程工作。
    (2)而直接执行run()方法，会把run方法当成一个main线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。
    (3)因此，调用start方法方可启动线程并使线程进入就绪状态，而run方法只是thread的一个普通方法调用，还是在主线程里执行。

#### 1.6 线程中的上下文切换
    多线程编程中一般线程的个数都大于CPU核心的个数，而一个CPU核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。
    【当前任务在执行完CPU时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。】

#### 1.7 Atomic原子类
     Atomic是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。

### 问题二：synchorized关键字相关面试题
#### 2.1 了解synchorized关键字
    synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。
    早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的Mutex Lock来实现的，Java的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的synchronized效率低的原因。

#### 2.2 使用synchorized关键字
    synchronized关键字最主要的三种使用方式：
    (1)修饰实例方法: 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁
    (2)修饰静态方法: 也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员。访问静态synchronized方法占用的锁是当前类的锁，而访问非静态synchronized方法占用的锁是当前实例对象锁。
    (3)修饰代码块: 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。

```java
//双重校验锁实现对象单例
public class Singleton {
    private volatile static Singleton uniqueInstance;
    private Singleton() {}
    public static Singleton getUniqueInstance() {
       //先判断对象是否已经实例过，没有实例化过才进入加锁代码
        if (uniqueInstance == null) {
            //类对象加锁
            synchronized (Singleton.class) {
                if (uniqueInstance == null) {
                    uniqueInstance = new Singleton();
                }
            }
        }
        return uniqueInstance;
    }
}
```

    另外，需要注意uniqueInstance采用volatile关键字修饰也是很有必要。
    uniqueInstance = new Singleton();这行代码其实是分为三步执行：
    1)为uniqueInstance分配内存空间
    2)初始化uniqueInstance
    3)将uniqueInstance指向分配的内存地址
    但是由于JVM具有指令重排的特性，执行顺序有可能变成 1->3->2。指令重排在单线程环境下不会出先问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程T1执行了1和3，此时T2调用getUniqueInstance()后发现uniqueInstance不为空，因此返回uniqueInstance，但此时uniqueInstance还未被初始化。
    使用volatile可以禁止JVM的指令重排，保证在多线程环境下也能正常运行。

#### 2.3 synchorized底层原理(同步代码块)
    synchronized同步语句块的实现使用的是monitorenter和monitorexit指令，其中monitorenter指令指向同步代码块的开始位置，monitorexit指令则指明同步代码块的结束位置。 当执行monitorenter指令时，线程试图获取锁也就是获取monitor的持有权【monitor对象存在于每个Java对象的对象头中，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因】。当计数器为0则可以成功获取，获取后将锁计数器设为1，相应的在执行monitorexit指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。

#### 2.4 synchorized底层优化
    (1)偏向锁
    它的意思是会偏向于第一个获得它的线程，如果在接下来的执行中，该锁没有被其他线程获取，那么持有偏向锁的线程就不需要进行同步。引入偏向锁是为了在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。偏向锁在无竞争的情况下会把整个同步都消除掉。
    (2)轻量级锁
    倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)。轻量级锁不是为了代替重量级锁，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗，因为使用轻量级锁时，不需要申请互斥量。另外，轻量级锁的加锁和解锁都用到了CAS操作。
    轻量级锁能够提升程序同步性能的依据是“对于绝大部分锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用CAS操作避免了使用互斥操作的开销。但如果存在锁竞争，除了互斥量开销外，还会额外发生CAS操作，因此在有锁竞争的情况下，轻量级锁比传统的重量级锁更慢！如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！
    (3)自旋锁
    轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。一般线程持有锁的时间都不是太长，所以仅仅为了这一点时间去挂起线程/恢复线程是得不偿失的。 所以，虚拟机的开发团队就这样去考虑：“我们能不能让后面来的请求获取锁的线程等待一会而不被挂起呢？看看持有锁的线程是否很快就会释放锁”。为了让一个线程等待，我们只需要让线程执行一个忙循环（自旋），这项技术就叫做自旋。
    对于互斥锁，如果资源已经被占用，资源申请者只能进入睡眠状态。但是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁。
    (4)锁消除
    它指的就是虚拟机即使编译器在运行时，如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间。

#### 2.5 Lock与Synchronized的区别
    (1)Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现，synchronized是在JVM层面上实现的，不但可以通过一些监控工具监控synchronized的锁定，而且在代码执行时出现异常，JVM会自动释放锁定，但是使用Lock则不行，lock是通过代码实现的，要保证锁定一定会被释放，就必须将unLock()放到finally{} 中；
    (2)synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；
    (3)Lock可以让等待锁的线程响应中断，线程可以中断去干别的事务，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；
    (4)通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。
    (5)Lock可以提高多个线程进行读操作的效率。
    整体上来说Lock是synchronized的扩展版，Lock提供了无条件的、可轮询的、定时的、可中断的、可多条件队列的锁操作。

#### 2.6 synchorized与ReentrantLock的区别
    (1)两者都是可重入锁。
    “可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。
    (2)synchronized依赖于JVM而ReentrantLock依赖于API
    synchronized是依赖于JVM实现的，前面我们也讲到了虚拟机团队在JDK1.6为synchronized关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReentrantLock是JDK层面实现的（也就是API层面，需要lock()和unlock()方法配合try/finally语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。
    (3)ReentrantLock比synchronized增加了一些高级功能
       (a)等待可中断
       ReentrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。
       (b)可实现公平锁
       ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。
       (c)可实现选择性通知
       synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition()方法。Condition可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 
       在使用notify()/notifyAll()方法进行通知时，被通知的线程是由JVM选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。

### 问题三：java内存模型
#### 3.1 并发编程的模型分类
    在并发编程需要处理的两个关键问题是：线程之间如何通信 和 线程之间如何同步。
    (1)通信
    通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。
      (a)在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。
      (b)在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。
    (2)同步
    同步是指程序用于控制不同线程之间操作发生相对顺序的机制。
      (a)在共享内存的并发模型里，同步是显式进行的。必须显式指定某个方法或某段代码需要在线程之间互斥执行。
      (b)在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。
    Java并发采用的是共享内存模型，Java线程之间的通信总是隐式进行。

#### 3.2 java内存模型
    (1)在Java中，所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间共享。局部变量、方法定义参数和异常处理器参数不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。
    (2)Java线程之间的通信由Java内存模型（JMM）控制。JMM决定了一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程与主内存之间的抽象关系：线程之间的共享变量存储在主内存中，每一个线程都有一个自己私有的本地内存，本地内存中存储了该变量以读／写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。
    (3)volatile关键字的主要作用就是保证变量的可见性然后还有一个作用是防止指令重排序。

#### 3.3 synchronized关键字和volatile关键字比较
    (1)volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。但是volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块。
    (2)多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞
    (3)volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。
    (4)volatile关键字主要用于解决变量在多个线程之间的可见性，而synchronized关键字解决的是多个线程之间访问资源的同步性。

#### 3.4 ThreadLocal简介及原理
    (1)简介
    通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。而ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本，他们可以使用get()和set()方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。
    (2)原理
    最终的变量是放在了当前线程的ThreadLocalMap中，并不是存在ThreadLocal上，ThreadLocal可以理解为只是ThreadLocalMap的封装，传递了变量值。ThrealLocal类中可以通过Thread.currentThread()获取到当前线程对象后，直接通过getMap(Thread t)可以访问到该线程的ThreadLocalMap对象。
    每个Thread中都具备一个ThreadLocalMap，而ThreadLocalMap可以存储以ThreadLocal为key的键值对。 比如我们在同一个线程中声明了两个ThreadLocal对象的话，会使用Thread内部仅有那个ThreadLocalMap存放数据的，ThreadLocalMap的key就是ThreadLocal对象，value就是ThreadLocal对象调用set方法设置的值。ThreadLocal为map结构是为了让每个线程可以关联多个ThreadLocal变量。这也就解释了ThreadLocal声明的变量为什么在每一个线程都有自己的专属本地变量。

#### 3.5 ThreadLocal内存泄漏问题
    ThreadLocalMap中使用的key为ThreadLocal的弱引用,而value是强引用。所以，如果ThreadLocal没有被外部强引用的情况下，在垃圾回收的时候key会被清理掉，而value不会被清理掉。这样一来，ThreadLocalMap中就会出现key为null的Entry。假如我们不做任何措施的话，value永远无法被GC回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用set()、get()、remove()方法的时候，会清理掉key为null的记录。

###问题四：线程池相关面试题
#### 4.1 为什么使用线程池
    (1)创建和销毁线程需要时间，如果创建和销毁的时间远大于线程执行的时间，反而得不偿失。
    (2)线程也需要占用内存空间，大量的线程会抢占宝贵的内存资源，可能会导致out of memory异常。且大量的线程回收也会给GC带来很大的压力，延长GC的停顿时间。
    (3)大量的线程也会抢占cpu的资源，cpu不停的在各个线程上下文切换中，反而没有时间去处理线程运行的时候该处理的任务。
    因此，为了避免频繁的创建和销毁线程，让创建的线程进行复用，就有了线程池的概念。线程池里会维护一部分活跃线程，如果有需要，就去线程池里取线程使用，用完即归还到线程池里，免去了创建和销毁线程的开销，且线程池也会限制线程的数量。
----
    【使用线程池的好处】
    (1)降低资源消耗。 通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
    (2)提高响应速度。 当任务到达时，任务可以不需要的等到线程创建就能立即执行。
    (3)提高线程的可管理性。 线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

#### 4.2 线程池的类型及原理
    (1)固定大小线程池FixedThreadPool
       适用于处理CPU密集型的任务，确保CPU在长期被工作线程使用的情况下，尽可能少的分配线程即可。
       1)特点：
          它是固定大小的线程池，其核心线程数和最大线程数大小一样。并且阻塞队列用的是LinkedBlockingQueue，也就是说线程最大数这个参数基本失效了，所以不会出现外包线程的存在，也可以认为keepAliveTime参数是一个摆设，除非allowCoreThreadTimeOut方法的调用。
       2)工作机制：
          (a)线程数少于核心线程数(设置的线程数)时，新建线程执行任务;
          (b)线程数等于核心线程数时，将任务加入阻塞队列。由于队列容量非常大(Integer.MAX_VALUE)，可以一直加加加，当线程池中的任务比较特殊时，比如关于数据库长时间的IO操作，可能导致OOM;
          (c)执行完任务的线程反复去队列中取任务执行
    (2)单线程线程池SingleThreadExecutor
       适用于串行执行任务的场景，每个任务必须按顺序执行，不需要并发执行。
       1)特点：
          核心线程数和最大线程数大小一样且都是1，keepAliveTime为0，阻塞队列是LinkedBlockingQueue
       2)工作机制：
          (a)线程池中没有线程时，新建一个线程执行任务
          (b)有一个线程以后，将任务加入阻塞队列，不停加加加
          (c)唯一的这一个线程不停地去队列里取任务执行
    (3)可缓存线程池CachedThreadPool
       用于并发执行大量短期的小任务。
       1)特点：
          (a)核心线程数为0，且最大线程数为Integer.MAX_VALUE，阻塞队列是SynchronousQueue；
          (b)SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作才能执行，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue
          (c)当提交任务的速度大于处理任务的速度时，每次提交一个任务，就必然会创建一个线程。极端情况下会创建过多的线程，耗尽CPU和内存资源。由于空闲60秒的线程会被终止，长时间保持空闲的CachedThreadPool不会占用任何资源。
       2)工作机制：
          (a)没有核心线程，直接向SynchronousQueue中提交任务
          (b)如果有空闲线程，就去取出任务执行；如果没有空闲线程，就新建一个
          (c)执行完任务的线程有60秒生存时间，如果在这个时间内可以接到新任务，就可以继续活下去，否则就拜拜。
    (4)ScheduledThreadPool
       用于需要多个后台线程执行周期任务，同时需要限制线程数量的场景。
       1)特点：
          最大线程数为Integer.MAX_VALUE，阻塞队列是DelayedWorkQueue。
          ScheduledThreadPoolExecutor添加任务提供了另外两个方法：
              (a)scheduleAtFixedRate() ：按某种速率周期执行
              (b)scheduleWithFixedDelay()：在某个延迟后执行
          两种方法的内部实现都是创建了一个ScheduledFutureTask对象封装了任务的延迟执行时间及执行周期，并调用decorateTask()方法转成RunnableScheduledFuture对象，然后添加到延迟队列中。
          DelayQueue中封装了一个优先级队列，会对队列中的ScheduledFutureTask进行排序，两个任务的执行time不同时，time小的先执行；否则比较添加到队列中的ScheduledFutureTask的顺序号sequenceNumber，先提交的先执行。
       2)工作机制：
          调用上面两个方法添加一个任务，线程池中的线程从DelayQueue中取任务，然后执行任务。
          (a)线程从DelayQueue中获取time大于等于当前时间的ScheduledFutureTask
          (b)执行完后修改这个task的time为下次被执行的时间
          (c)然后再把这个task放回队列中DelayQueue.add()

#### 4.3 线程池的工作队列
    (1)有界队列ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按FIFO（先进先出）原则对元素进行排序。
    (2)无界队列LinkedBlockingQueue：一个基于链表结构的阻塞队列，此队列按FIFO（先进先出）排序元素，吞吐量通常要高于ArrayBlockingQueue。
    (3)同步队列SynchronousQueue: 一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue。
    (4)延迟队列DelayQueue：一个任务定时周期的延迟执行的队列。根据指定的执行时间从小到大排序，否则根据插入到队列的先后排序。
    (5)优先级队列PriorityBlockingQueue: 一个具有优先级得无限阻塞队列。

#### 4.4 线程池的重要参数
```java
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler) {
    if (corePoolSize < 0 ||
        maximumPoolSize <= 0 ||
        maximumPoolSize < corePoolSize ||
        keepAliveTime < 0)
        throw new IllegalArgumentException();
    if (workQueue == null || threadFactory == null || handler == null)
        throw new NullPointerException();
    this.corePoolSize = corePoolSize;
    this.maximumPoolSize = maximumPoolSize;
    this.workQueue = workQueue;
    this.keepAliveTime = unit.toNanos(keepAliveTime);
    this.threadFactory = threadFactory;
    this.handler = handler;
}
```

    (1)corePoolSize：核心线程池的大小，在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中
    (2)maximumPoolSize：线程池最大线程数
    (3)keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止
    (4)unit：参数keepAliveTime的时间单位TimeUtil类的枚举类（DAYS、HOURS、MINUTES、SECONDS等）
    (5)workQueue：阻塞队列，用来存储等待执行的任务
    (6)threadFactory：线程工厂，主要用来创建线程
    (7)handler：拒绝处理任务的策略
        AbortPolicy：丢弃任务并抛出RejectedExecutionException 异常。（默认这种）
        DiscardPolicy：也是丢弃任务，但是不抛出异常
        DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）
        CallerRunsPolicy：由调用线程处理该任务

#### 4.5 线程池执行任务流程
    (1)当有任务进入时，线程池创建线程去执行任务，直到核心线程数满为止
    (2)核心线程数量满了之后，任务就会进入一个缓冲的任务队列中
       (a)当任务队列为无界队列时，任务就会一直放入缓冲的任务队列中，不会和最大线程数量进行比较
       (b)当任务队列为有界队列时，任务先放入缓冲的任务队列中，当任务队列满了之后，才会将任务放入线程池，此时会拿当前线程数与线程池允许的最大线程数进行比较，如果超出了，则默认会抛出异常。如果没超出，然后线程池才会创建线程并执行任务，当任务执行完，又会将缓冲队列中的任务放入线程池中，然后重复此操作。

### 问题五：线程死锁及如何避免，锁分类
#### 5.1 什么是线程死锁
    多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。线程A持有资源2，线程B持有资源1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。

#### 5.2 死锁的必要条件
    (1)互斥条件：该资源任意一个时刻只由一个线程占用。
    (2)请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
    (3)不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
    (4)循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

#### 5.3如何避免死锁
    (1)破坏互斥条件：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。
    (2)破坏请求与保持条件：一次性申请所有的资源。
    (3)破坏不剥夺条件：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
    (4)破坏循环等待条件：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。

#### 5.4 锁分类
    (1)公平锁/非公平锁
    公平锁是指多个线程按照申请锁的顺序来获取锁。非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。对于Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS(AbstractQueuedSynchronizer)来实现线程调度，所以并没有任何办法使其变成公平锁。
    (2)可重入锁
    可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。说的有点抽象。对于Java ReentrantLock而言, 它是一个可重入锁，其名字是ReentrantLock重新进入锁。对于Synchronized而言,也是一个可重入锁。可重入锁的一个好处是可一定程度避免死锁。
    (3)独占锁/共享锁【互斥锁、读写锁是具体实现】
    独享锁是指该锁一次只能被一个线程所持有。共享锁是指该锁可被多个线程所持有。对于Java ReentrantLock而言，其是独享锁。但是对于Lock的另一个实现类ReentrantReadWriteLock，其读锁是共享锁，其写锁是独享锁。读锁的共享锁可保证并发读是非常高效的，读写，写读 ，写写的过程是互斥的。独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。对于Synchronized而言，当然是独享锁。
    (4)乐观锁/悲观锁
    乐观锁与悲观锁不是指具体的什么类型的锁，而是指看待并发同步的角度。
       (a)悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。
       (b)乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的。
    从上面的描述我们可以看出，悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。悲观锁在Java中的使用，就是利用各种锁。乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。
    (5)分段锁
    分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。
    我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。
    当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。
    但是，在统计size的时候，可就是获取hashmap全局信息的时候，就需要获取所有的分段锁才能统计。
    分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。
    (6)偏向锁/轻量级锁/重量级锁/自旋锁
    这四种锁是指锁的状态，并且是针对Synchronized。在Java 5通过引入锁升级的机制来实现高效Synchronized。这三种锁的状态是通过对象监视器在对象头中的字段来表明的。
       (a)偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。
       (b)轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。
       (c)重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。
       (d)自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。

#### 5.5 其他补充
    (1)Callable接口类似于Runnable，但是Runnable不会返回结果，并且无法抛出返回结果的异常，而Callable功能更强大一些，被线程执行后，可以返回值，这个返回值可以被Future拿到，也就是说Future可以拿到异步执行任务的返回值。可以认为是带有回调的Runnable。
    (2)Future接口表示异步任务，是还没有完成的任务给出的未来结果。所以说Callable用于产生结果，Future用于获取结果。
    (3)FutureTask
       在Java并发程序中FutureTask表示一个可以取消的异步运算。它有启动和取消运算、查询运算是否完成和取回运算结果等方法。只有当运算完成的时候结果才能取回，如果运算尚未完成get方法将会阻塞。一个FutureTask对象可以对调用了Callable和Runnable的对象进行包装，由于FutureTask也是调用了Runnable接口所以它可以提交给Executor来执行。

### 问题六：常见的并发容器及Java集合框架
#### 6.1 Arraylist与LinkedList区别
    (1)是否保证线程安全：ArrayList和LinkedList都是不同步的，也就是不保证线程安全；
    (2)底层数据结构：Arraylist底层使用的是Object数组；LinkedList底层使用的是双向链表数据结构。
    (3)插入和删除是否受元素位置的影响： 
        (a)ArrayList采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候，ArrayList会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是O(1)。但是如果要在指定位置i插入和删除元素的话add(int index,E element)时间复杂度就为O(n-i)。因为在进行上述操作的时候集合中第i和第i个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。
        (b)LinkedList采用链表存储，所以插入、删除元素时间复杂度不受元素位置的影响，都是近似O(1)而数组为近似O(n)。
    (4)是否支持快速随机访问：LinkedList不支持高效的随机元素访问，而ArrayList支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。
    (5)内存空间占用：ArrayList的空间浪费主要体现在在list列表的结尾会预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗比ArrayList更多的空间（因为要存放直接后继和直接前驱以及数据）。

#### 6.2 HashMap和HashTable区别
    (1)线程是否安全： HashMap是非线程安全的，HashTable是线程安全的；HashTable内部的方法基本都经过synchronized修饰，如果要保证线程安全的话就使用ConcurrentHashMap。
    (2)效率：因为线程安全的问题，HashMap要比HashTable效率高一点。另外，HashTable基本被淘汰，不要在代码中使用它；
    (3)对Null key和Null value的支持：
       (a)在HashMap中，null可以作为键，这样的键只有一个，可以有一个或多个键所对应的值为 null。
       (b)但是在HashTable中put进的键值只要有一个null，直接抛出NullPointerException。
    (4)初始容量大小和每次扩充容量大小的不同：
       (a)创建时如果不指定容量初始值，Hashtable默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap默认的初始化大小为16,之后每次扩充，容量变为原来的2倍。
       (b)创建时如果给定了容量初始值，那么Hashtable会直接使用你给定的大小，而HashMap会将其扩充为2的幂次方大小，也就是说HashMap总是使用2的幂作为哈希表的大小。
    (5)底层数据结构：JDK1.8以后的HashMap在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。 

#### 6.3 HashSet如何检查重复
    当把对象加入HashSet时，HashSet会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的hashcode值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同hashcode值的对象，这时会调用equals()方法来检查hashcode相等的对象是否真的相同。如果两者相同，HashSet就不会让加入操作成功。

#### 6.4 HashMap底层实现
    (1)实现原理
    JDK1.8之前HashMap底层是数组和链表结合在一起使用也就是链表散列。HashMap通过key的 hashCode经过扰动函数处理过后得到hash值，然后通过(n-1)&hash判断当前元素存放的位置（这里的n指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的hash值以及key是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。
    (2)HashMap的长度为什么是2的幂次方
       (a)为了能让HashMap存取高效，尽量较少碰撞，也就是要尽量把数据分配均匀。我们上面也讲到了过了，Hash值的范围值-2147483648到2147483647，前后加起来大概40亿的映射空间，只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。但问题是一个40亿长度的数组，内存是放不下的。所以这个散列值是不能直接拿来用的。用之前还要先做对数组的长度取模运算，得到的余数才能用来要存放的位置也就是对应的数组下标。这个数组下标的计算方法是(n-1)&hash（n代表数组长度）这也就解释了HashMap的长度为什么是2的幂次方。
       (b)取余(%)操作中如果除数是2的幂次则等价于与其除数减一的与(&)操作（也就是说 hash%length==hash&(length-1)的前提是length是2的n次方）并且采用二进制位操作 &相对于%能够提高运算效率，这就解释了HashMap的长度为什么是2的幂次方。

#### 6.5 ConcurrentHashMap和Hashtable的区别
    (1)底层数据结构：JDK1.7的ConcurrentHashMap底层采用分段的数组+链表实现，JDK1.8采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。Hashtable和JDK1.8 之前的HashMap的底层数据结构类似都是采用数组+链表的形式，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的；
    (2)实现线程安全的方式（重要）
       (a)在JDK1.7的时候，ConcurrentHashMap（分段锁）对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 到了JDK1.8的时候已经摒弃了Segment的概念，而是直接用Node数组+链表+红黑树的数据结构来实现，并发控制使用synchronized和CAS来操作。（JDK1.6以后对synchronized锁做了很多优化）整个看起来就像是优化过且线程安全的 HashMap，虽然在JDK1.8中还能看到Segment的数据结构，但是已经简化了属性，只是为了兼容旧版本；
       (b)Hashtable(同一把锁) :使用synchronized来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用put添加元素，另一个线程不能使用put添加元素，也不能使用get，竞争会越来越激烈效率越低。

#### 6.6 ConcurrentHashMap具体实现
    (1)首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。
    (2)ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment实现了ReentrantLock,所以Segment是一种可重入锁，扮演锁的角色。HashEntry用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组。
    (3)Segment的结构和HashMap类似，是一种数组和链表结构，一个Segment包含一个HashEntry数组，每个HashEntry是一个链表结构的元素，每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得对应的Segment的锁。

    JDK 1.8之后ConcurrentHashMap取消了Segment分段锁，采用CAS和synchronized来保证并发安全。数据结构跟HashMap1.8的结构类似，数组+链表/红黑二叉树。在链表长度超过一定阈值(8)时将链表（寻址时间复杂度为O(N)）转换为红黑树（寻址时间复杂度为O(log(N))。
    synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发，效率又提升N倍。
